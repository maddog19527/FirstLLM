{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/michaelgriffin/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import PreprocessingFunctions\n",
    "from PreprocessingFunctions import CleanText, StopWordFunc, sentimentanalyzervader, sentimentTextBlob, sentimentscoreTB\n",
    "from Lemmatizer import LemmatizeFunc, StemmerFunc\n",
    "from Emoji import Emoticon\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data and pull basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=pd.read_csv('covid19_tweets.csv')\n",
    "# tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Columns=tweets[['text','user_description','hashtags']].copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Preprocessing for Text Columns (Tweets, Usernames, Descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert user_description and hashtags to strings after error handling for CleanText function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Text_Columns:\n",
    "    Text_Columns[col]=Text_Columns[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Text_Columns:\n",
    "    Text_Columns[col]=Text_Columns[col].apply(Emoticon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Text_Columns:\n",
    "    Text_Columns[col]=Text_Columns[col].apply(CleanText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply StopWord and Lemmatization Functions to text-based columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Text_Columns:\n",
    "    Text_Columns[col]=Text_Columns[col].apply(StopWordFunc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Two Sentiment Analysis Tools to Label Tweets, comparing the Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Text_Columns:\n",
    "    Text_Columns[col]=Text_Columns[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Columns['sentimentNLTK']=Text_Columns['text'].apply(sentimentanalyzervader)\n",
    "\n",
    "Text_Columns['Neutral']=Text_Columns['sentimentNLTK'].apply(lambda x: x['neu'])\n",
    "Text_Columns['Positive']=Text_Columns['sentimentNLTK'].apply(lambda x: x['pos'])\n",
    "Text_Columns['Compound']=Text_Columns['sentimentNLTK'].apply(lambda x: x['compound'])\n",
    "Text_Columns['Negative']=Text_Columns['sentimentNLTK'].apply(lambda x: x['neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Columns['sentimentBLOB']=Text_Columns['text'].apply(sentimentTextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Columns['BLOB sentiment']=Text_Columns['sentimentBLOB'].apply(sentimentscoreTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  ['smelled', 'scent', 'hand', 'sanitizers', 'to...   \n",
      "1  ['hey', 'yankees', 'yankeespr', 'mlb', 'wouldn...   \n",
      "2  ['diane', 'wdunlap', 'realdonaldtrump', 'trump...   \n",
      "3  ['brookbanktv', 'one', 'gift', 'covid', 'give'...   \n",
      "4  ['july', 'media', 'bulletin', 'novel', 'corona...   \n",
      "\n",
      "                                    user_description  \\\n",
      "0  ['wednesday', 'addams', 'disney', 'princess', ...   \n",
      "1  ['husband', 'father', 'columnist', 'commentato...   \n",
      "2  ['christian', 'catholic', 'conservative', 'rea...   \n",
      "3  ['browns', 'indians', 'clevelandproud', 'cavs'...   \n",
      "4  ['penofficial', 'twitter', 'handle', 'departme...   \n",
      "\n",
      "                          hashtags  \\\n",
      "0                          ['nan']   \n",
      "1                          ['nan']   \n",
      "2                        ['covid']   \n",
      "3                        ['covid']   \n",
      "4  ['coronavirusupdates', 'covid']   \n",
      "\n",
      "                                       sentimentNLTK  Neutral  Positive  \\\n",
      "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...      1.0       0.0   \n",
      "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...      1.0       0.0   \n",
      "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...      1.0       0.0   \n",
      "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...      1.0       0.0   \n",
      "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...      1.0       0.0   \n",
      "\n",
      "   Compound  Negative  sentimentBLOB BLOB sentiment  \n",
      "0       0.0       0.0       0.250000       positive  \n",
      "1       0.0       0.0       0.000000        neutral  \n",
      "2       0.0       0.0       0.000000        neutral  \n",
      "3       0.0       0.0       0.357143       positive  \n",
      "4       0.0       0.0       0.000000        neutral  \n"
     ]
    }
   ],
   "source": [
    "print(Text_Columns.head())\n",
    "with open('Text_Columns.pkl', 'wb') as file:\n",
    "    pickle.dump(Text_Columns, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
