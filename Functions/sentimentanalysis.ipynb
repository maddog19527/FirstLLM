{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/michaelgriffin/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from nltk import FreqDist\n",
    "import PreprocessingFunctions\n",
    "import ast\n",
    "import pandas as pd\n",
    "from Lemmatizer import StemmerFunc\n",
    "from PreprocessingFunctions import list_features\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk.classify.util\n",
    "with open('Text_Columns.pkl', 'rb') as file:\n",
    "    Text_Columns=pickle.load(file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ['smelled', 'scent', 'hand', 'sanitizers', 'to...\n",
      "1    ['hey', 'yankees', 'yankeespr', 'mlb', 'wouldn...\n",
      "2    ['diane', 'wdunlap', 'realdonaldtrump', 'trump...\n",
      "3    ['brookbanktv', 'one', 'gift', 'covid', 'give'...\n",
      "4    ['july', 'media', 'bulletin', 'novel', 'corona...\n",
      "Name: text, dtype: object\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(Text_Columns['text'].head())\n",
    "print(type(Text_Columns['text'].iloc[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Columns['text']=Text_Columns['text'].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [smelled, scent, hand, sanitizers, today, some...\n",
      "1    [hey, yankees, yankeespr, mlb, wouldnt, made, ...\n",
      "2    [diane, wdunlap, realdonaldtrump, trump, never...\n",
      "3    [brookbanktv, one, gift, covid, give, apprecia...\n",
      "4    [july, media, bulletin, novel, coronavirusupda...\n",
      "Name: text, dtype: object\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(Text_Columns['text'].head())\n",
    "print(type(Text_Columns['text'].iloc[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text_Columns['text']=Text_Columns['text'].apply(StemmerFunc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [smelled, scent, hand, sanitizers, today, some...\n",
      "1    [hey, yankees, yankeespr, mlb, wouldnt, made, ...\n",
      "2    [diane, wdunlap, realdonaldtrump, trump, never...\n",
      "3    [brookbanktv, one, gift, covid, give, apprecia...\n",
      "4    [july, media, bulletin, novel, coronavirusupda...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Text_Columns['text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "all_words=[word for row in Text_Columns['text'] for word in row]\n",
    "print(type(all_words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smelled', 'scent', 'hand', 'sanitizers', 'today', 'someone', 'past', 'would', 'think', 'intoxicated', 'httpstcoqzvybrogb', 'hey', 'yankees', 'yankeespr', 'mlb', 'wouldnt', 'made', 'sense', 'players', 'pay', 'respects', 'httpstcoqvwzgypu', 'diane', 'wdunlap', 'realdonaldtrump', 'trump', 'never', 'claimed', 'covid', 'hoax', 'claim', 'effort', 'httpstcojkkvhwhb', 'brookbanktv', 'one', 'gift', 'covid', 'give', 'appreciation', 'simple', 'things', 'always', 'around', 'httpstcozpoalfxcw', 'july', 'media', 'bulletin', 'novel', 'coronavirusupdates', 'covid', 'kansalrohit', 'drsyedsehrish', 'airnewsalerts', 'ani', 'httpstcomneecsjhh', 'coronavirus', 'covid', 'deaths', 'continue', 'rise', 'almost', 'bad', 'ever', 'politicians', 'businesses', 'want', 'httpstcohxmhooxxc', 'covid', 'change', 'work', 'general', 'recruiting', 'specifically', 'via', 'proactivetalent', 'recruiting', 'httpstcobjzxzgpmbk', 'wear', 'face', 'coverings', 'shopping', 'includes', 'visit', 'local', 'community', 'pharmacy', 'httpstcoosuqkdd', 'praying', 'good', 'health', 'recovery', 'chouhanshivraj', 'covid', 'covidpositive', 'pope', 'god', 'prophet', 'sadhu', 'sundar', 'selvaraj']\n"
     ]
    }
   ],
   "source": [
    "print(all_words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_freq=FreqDist(all_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features=[word for word, freq in all_words_freq.most_common(1000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['covid', 'cases', 'coronavirus', 'new', 'amp', 'people', 'pandemic', 'deaths', 'us', 'health', 'one', 'positive', 'total', 'today', 'get', 'india', 'need', 'like', 'day', 'help', 'mask', 'realdonaldtrump', 'trump', 'last', 'world', 'time', 'vaccine', 'news', 'many', 'know', 'august', 'first', 'th', 'update', 'reported', 'masks', 'due', 'virus', 'spread', 'even', 'testing', 'still', 'number', 'lockdown', 'back', 'death', 'tested', 'please', 'good', 'take']\n"
     ]
    }
   ],
   "source": [
    "print(word_features[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_features(text, word_features):\n",
    "    words=set(text)\n",
    "    features={}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)]=(word in words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Columns['Feature Sets']=Text_Columns['text'].apply(lambda x: list_features(x, word_features))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Columns['Feature Sets']=Text_Columns['Feature Sets'].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Set=list(zip(Text_Columns['Feature Sets'],Text_Columns['BLOB sentiment']))\n",
    "TrainSet=Set[1800:]\n",
    "TestSet=Set[:1800]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179108\n"
     ]
    }
   ],
   "source": [
    "print(len(Set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier=NaiveBayesClassifier.train(TrainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.00]%\n"
     ]
    }
   ],
   "source": [
    "Accuracy=nltk.classify.util.accuracy(Classifier, TestSet)\n",
    "print(f'Accuracy: {Accuracy * 100:.2f}]%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(real) = True           positi : neutra =    374.6 : 1.0\n",
      "      contains(actually) = True           positi : neutra =    198.1 : 1.0\n",
      "        contains(deadly) = True           positi : neutra =    147.8 : 1.0\n",
      "          contains(much) = True           positi : neutra =    118.3 : 1.0\n",
      "        contains(really) = True           positi : neutra =     97.0 : 1.0\n",
      "     contains(currently) = True           positi : neutra =     95.3 : 1.0\n",
      "          contains(york) = True           positi : neutra =     74.2 : 1.0\n",
      "       contains(finally) = True           positi : neutra =     71.3 : 1.0\n",
      "        contains(nearly) = True           positi : neutra =     68.7 : 1.0\n",
      "    contains(especially) = True           positi : neutra =     66.7 : 1.0\n",
      "    contains(distancing) = True           positi : neutra =     23.7 : 1.0\n",
      "   contains(fountainpen) = True           neutra : positi =     22.2 : 1.0\n",
      "        contains(sooner) = True           positi : neutra =     21.2 : 1.0\n",
      "     contains(component) = True           neutra : positi =     12.9 : 1.0\n",
      "contains(coronavirusupdate) = True           positi : neutra =     11.3 : 1.0\n",
      "           contains(gmt) = True           positi : neutra =     11.0 : 1.0\n",
      "          contains(copy) = True           neutra : positi =     10.1 : 1.0\n",
      "          contains(type) = True           neutra : positi =      6.7 : 1.0\n",
      "         contains(hours) = True           positi : neutra =      6.7 : 1.0\n",
      "      contains(identify) = True           positi : neutra =      5.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "Classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "tester_tweet = \"!\"\n",
    "\n",
    "test_tokens = word_tokenize(tester_tweet)\n",
    "\n",
    "test_features = list_features(test_tokens, word_features)\n",
    "\n",
    "classification = Classifier.classify(test_features)\n",
    "print(classification)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
