{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import PreprocessingFunctions\n",
    "from PreprocessingFunctions import CleanText, StopWordFunc\n",
    "from Emoji import Emoticon\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data and pull basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=pd.read_csv('covid19_tweets.csv')\n",
    "# tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()\n",
    "tweets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numerical_Columns=['user_followers','user_favourites','user_friends']\n",
    "Date_Time_Columns=tweets[['user_created','date']].copy(deep=True)\n",
    "Boolean_Columns=['is_retweet','user_verified']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Columns=tweets[['text','user_description','hashtags']].copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data columns to date-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in Date_Time_Columns:\n",
    "    tweets[col]=pd.to_datetime(tweets[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Preprocessing for Text Columns (Tweets, Usernames, Descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets['text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert user_description and hashtags to strings after error handling for CleanText function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Text_Columns:\n",
    "    Text_Columns[col]=Text_Columns[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Text_Columns:\n",
    "    Text_Columns[col]=Text_Columns[col].apply(CleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['user_description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Text_Columns:\n",
    "    Emoticon(Text_Columns['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply StopWord and Lemmatization Functions to text-based columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Text_Columns:\n",
    "    Text_Columns[col]=Text_Columns[col].apply(StopWordFunc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Text_Columns:\n",
    "    Text_Columns[col]=Text_Columns[col].fillna('').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ['smelled', 'scent', 'hand', 'sanitizers', 'to...\n",
      "1    ['hey', 'yankee', 'yankeespr', 'mlb', 'wouldnt...\n",
      "2    ['diane', 'wdunlap', 'realdonaldtrump', 'trump...\n",
      "3    ['brookbanktv', 'one', 'gift', 'covid', 'give'...\n",
      "4    ['july', 'medium', 'bulletin', 'novel', 'coron...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Text_Columns['text'].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
